{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9bef1a85",
   "metadata": {},
   "source": [
    "Mapping Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "86a51bc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "from torch import nn \n",
    "\n",
    "class Mapping_Network(nn.Module):\n",
    "    def __init__(self , z_dim , w_dim):\n",
    "        super(Mapping_Network , self).__init__()\n",
    "        self.mapping = nn.Sequential(\n",
    "            nn.Linear(z_dim , w_dim),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Linear(w_dim , w_dim),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Linear(w_dim , w_dim),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Linear(w_dim , w_dim),\n",
    "            nn.LeakyReLU(0.2)\n",
    "            )\n",
    "\n",
    "    def forward(self , z):\n",
    "        return self.mapping(z)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "639ca7cc",
   "metadata": {},
   "source": [
    "Noise Injection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "190f10fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Inject_Noise(nn.Module):\n",
    "    def __init__(self , channels):\n",
    "        super(Inject_Noise , self).__init__()\n",
    "        self.weight = nn.Parameter(torch.zeros(1,channels ,  1 , 1))\n",
    "\n",
    "    def forward(self , x):\n",
    "        noise = torch.randn((x.shape[0], 1 , x.shape[2] , x.shape[3]) ,device = x.device )\n",
    "        return x + self.weight * noise"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09743f84",
   "metadata": {},
   "source": [
    "AdaIN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "039b96cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AdaIN( nn.Module):\n",
    "    def __init__(self , channels , x_dim):\n",
    "        super(AdaIN , self).__init__()\n",
    "        self.Instnorm = nn.InstanceNorm2d(channels)\n",
    "        self.style_scale =  nn.Linear(x_dim , channels)\n",
    "        self.style_bias = nn.Linear(x_dim , channels)\n",
    "\n",
    "    def forward(self , x, w):\n",
    "        x = self.Instnorm(x)\n",
    "        scale =  self.style_scale(w).unsqueeze(2).unsqueeze(3)\n",
    "        bias = self.style_bias(w).unsqueeze(2).unsqueeze(3)\n",
    "        return x *scale + bias"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc8bb812",
   "metadata": {},
   "source": [
    "Style Block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "335d166c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Style_Block(nn.Module):\n",
    "    def __init__(self , in_channels , out_channels , w_dim , upsample = True):\n",
    "        super().__init__()\n",
    "        self.upsample = nn.Upsample(scale_factor = 2) if upsample else None\n",
    "        self.conv = nn.Conv2d( in_channels , out_channels , kernel_size = 3 , padding = 1)\n",
    "        self.noise = Inject_Noise(out_channels)\n",
    "        self.lrelu = nn.LeakyReLU(0.2)\n",
    "        self. adain = AdaIN(out_channels , w_dim)\n",
    "\n",
    "    def forward(self , x, w):\n",
    "        if self.upsample:\n",
    "            x = self.upsample(x)\n",
    "    \n",
    "        x = self.conv(x)\n",
    "        x = self.noise(x)\n",
    "        x = self.lrelu(x)\n",
    "        x = self.adain(x,w)\n",
    "        return x\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72523c2d",
   "metadata": {},
   "source": [
    "Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "67b562e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Generator(nn.Module):\n",
    "    def __init__(self , z_dim , w_dim ,img_channels = 1):\n",
    "        super(Generator , self ).__init__()\n",
    "        self.mapnet =  Mapping_Network(z_dim , w_dim)\n",
    "        self.lr_cnst = nn.Parameter(torch.randn(1,512,4,4))\n",
    "\n",
    "        self.sb1 = Style_Block(512 , 256 , w_dim , upsample =  True)\n",
    "        self.sb2 = Style_Block(256 , 128 , w_dim , upsample = True)\n",
    "        self.sb3 = Style_Block(128, 64 ,  w_dim , upsample =  True)\n",
    "\n",
    "        self.col = nn.Conv2d(64 , img_channels , kernel_size = 1)\n",
    "\n",
    "\n",
    "    def forward(self , z ):\n",
    "        w = self.mapnet(z)\n",
    "        x = self.lr_cnst.repeat(z.shape[0] , 1, 1, 1)\n",
    "        x = self.sb1(x,w)\n",
    "        x = self.sb2(x,w)\n",
    "        x = self.sb3(x,w)\n",
    "\n",
    "        return torch.tanh(self.col(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8d512e9",
   "metadata": {},
   "source": [
    "Discriminator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "e395985c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Discriminator(nn.Module):\n",
    "    def __init__(self , img_channels = 1):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Conv2d(img_channels , 64 , kernel_size = 3 ,stride = 2, padding = 1),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Conv2d(64 , 128 , kernel_size = 3 ,stride = 2, padding = 1),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Conv2d(128 , 256 , kernel_size = 3 ,stride = 2, padding = 1),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(256 * 4 * 4 ,1)\n",
    "\n",
    "\n",
    "        )\n",
    "\n",
    "\n",
    "    def forward(self , x):\n",
    "        return self.net(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "ffd807b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8\n"
     ]
    }
   ],
   "source": [
    "print(len(list(critic.parameters()))) \n",
    "# This should be 8 (4 conv/linear layers, each with weight and bias)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36c29c51",
   "metadata": {},
   "source": [
    "Gradient Penalty "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "24a1e326",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Gradient_Penalty (critc , real , fake , device = 'cpu'):\n",
    "    BATCH_SIZE ,C , H , W = real.shape\n",
    "    alpha = torch.rand((BATCH_SIZE , 1, 1, 1)).repeat(1 , C , H , W).to(device)\n",
    "    interpolated_images = real * alpha +fake * (1-alpha)\n",
    "    interpolated_images.requires_grad_(True)\n",
    "\n",
    "    mix_score = critc(interpolated_images)\n",
    "\n",
    "    gradient = torch.autograd.grad(\n",
    "        inputs = interpolated_images , \n",
    "        outputs = mix_score , \n",
    "        grad_outputs = torch.ones_like(mix_score) ,\n",
    "        create_graph = True ,\n",
    "        retain_graph = True\n",
    "\n",
    "    )[0]\n",
    "\n",
    "\n",
    "    gradient = gradient.view(gradient.shape[0] , -1)\n",
    "    gradient_norm = gradient.norm(2 , dim = 1)\n",
    "    gradient_penalty = torch.mean((gradient_norm - 1) ** 2)\n",
    "    return gradient_penalty"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2b0bd51",
   "metadata": {},
   "source": [
    "Training Loop "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "a60d3855",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim \n",
    "\n",
    "DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "Z_DIM = 512\n",
    "W_DIM = 512\n",
    "LAMBDA_GP = 10\n",
    "BATCH_SIZE = 64\n",
    "LR = 1e-4\n",
    "\n",
    "gen = Generator(Z_DIM , W_DIM).to(DEVICE)\n",
    "critic = Discriminator().to(DEVICE)\n",
    "opt_gen = optim.Adam(gen.parameters() , lr = LR , betas = (0.0 , 0.99))\n",
    "opt_critic = optim.Adam(critic.parameters() , lr = LR , betas = (0.0 , 0.99))\n",
    "\n",
    "def train_step(real):\n",
    "    real_images = real.to(DEVICE)\n",
    "    cur_batch_size = real_images.shape[0]\n",
    "\n",
    "    for _ in range(5):\n",
    "        noise = torch.randn(cur_batch_size , Z_DIM).to(DEVICE)\n",
    "        fake_images = gen(noise)\n",
    "        critic_real = critic(real_images)\n",
    "        critic_fake = critic(fake_images.detach())\n",
    "        gp = Gradient_Penalty(critic , real_images , fake_images.detach() , device = DEVICE)\n",
    "        loss_critic = -(torch.mean(critic_real) - torch.mean(critic_fake)) + Lambda_GP * gp\n",
    "\n",
    "        critic.zero_grad()\n",
    "        loss_critic.backward()\n",
    "        opt_critic.step()\n",
    "\n",
    "    gen_fake = critic(fake_images)\n",
    "    loss_gen = -torch.mean(gen_fake)\n",
    "    gen.zero_grad()\n",
    "    loss_gen.backward()\n",
    "    opt_gen.step()\n",
    "\n",
    "\n",
    "    return loss_gen.item() , loss_critic.item()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29c3838c",
   "metadata": {},
   "source": [
    "Dataloading and pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "02292abb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [0/50] Batch 0/938 Loss D: 0.0055, loss G: 8.5647\n",
      "Epoch [0/50] Batch 100/938 Loss D: 0.6069, loss G: -5.9600\n",
      "Epoch [0/50] Batch 200/938 Loss D: 8.6193, loss G: -6.6609\n",
      "Epoch [0/50] Batch 300/938 Loss D: 8.1069, loss G: -8.7349\n",
      "Epoch [0/50] Batch 400/938 Loss D: 12.5523, loss G: -8.5296\n",
      "Epoch [0/50] Batch 500/938 Loss D: 21.8382, loss G: -12.0537\n",
      "Epoch [0/50] Batch 600/938 Loss D: 16.4892, loss G: -12.2607\n",
      "Epoch [0/50] Batch 700/938 Loss D: -1.5364, loss G: -12.7820\n",
      "Epoch [0/50] Batch 800/938 Loss D: 6.9173, loss G: -4.3665\n",
      "Epoch [0/50] Batch 900/938 Loss D: 19.9522, loss G: -4.0234\n",
      "Epoch [1/50] Batch 0/938 Loss D: 21.5159, loss G: -4.3055\n",
      "Epoch [1/50] Batch 100/938 Loss D: 15.6575, loss G: -3.6999\n",
      "Epoch [1/50] Batch 200/938 Loss D: 19.1030, loss G: -4.2587\n",
      "Epoch [1/50] Batch 300/938 Loss D: 20.9280, loss G: -4.7088\n",
      "Epoch [1/50] Batch 400/938 Loss D: 33.5932, loss G: -5.4078\n",
      "Epoch [1/50] Batch 500/938 Loss D: 17.4851, loss G: -3.6215\n",
      "Epoch [1/50] Batch 600/938 Loss D: 27.9810, loss G: -3.7602\n",
      "Epoch [1/50] Batch 700/938 Loss D: 25.2985, loss G: -6.0078\n",
      "Epoch [1/50] Batch 800/938 Loss D: 32.6426, loss G: -3.8975\n",
      "Epoch [1/50] Batch 900/938 Loss D: 35.8782, loss G: -4.3227\n",
      "Epoch [2/50] Batch 0/938 Loss D: 35.1520, loss G: -4.1503\n",
      "Epoch [2/50] Batch 100/938 Loss D: 33.2915, loss G: -3.5075\n",
      "Epoch [2/50] Batch 200/938 Loss D: 39.6949, loss G: -4.9920\n",
      "Epoch [2/50] Batch 300/938 Loss D: 39.3129, loss G: -4.1729\n",
      "Epoch [2/50] Batch 400/938 Loss D: 37.7487, loss G: -3.1698\n",
      "Epoch [2/50] Batch 500/938 Loss D: 47.6382, loss G: -5.0823\n",
      "Epoch [2/50] Batch 600/938 Loss D: 37.5208, loss G: -2.7661\n",
      "Epoch [2/50] Batch 700/938 Loss D: 40.1857, loss G: -3.2046\n",
      "Epoch [2/50] Batch 800/938 Loss D: 45.0395, loss G: -3.8813\n",
      "Epoch [2/50] Batch 900/938 Loss D: 42.8653, loss G: -3.2455\n",
      "Epoch [3/50] Batch 0/938 Loss D: 42.3200, loss G: -4.3925\n",
      "Epoch [3/50] Batch 100/938 Loss D: 54.6430, loss G: -3.9092\n",
      "Epoch [3/50] Batch 200/938 Loss D: 50.7198, loss G: -2.5005\n",
      "Epoch [3/50] Batch 300/938 Loss D: 45.3462, loss G: -3.0752\n",
      "Epoch [3/50] Batch 400/938 Loss D: 57.0785, loss G: -3.1451\n",
      "Epoch [3/50] Batch 500/938 Loss D: 46.4399, loss G: -3.3835\n",
      "Epoch [3/50] Batch 600/938 Loss D: 41.0964, loss G: -3.2700\n",
      "Epoch [3/50] Batch 700/938 Loss D: 45.3098, loss G: -2.9919\n",
      "Epoch [3/50] Batch 800/938 Loss D: 45.5149, loss G: -3.0723\n",
      "Epoch [3/50] Batch 900/938 Loss D: 54.8484, loss G: -2.9616\n",
      "Epoch [4/50] Batch 0/938 Loss D: 53.8096, loss G: -3.1132\n",
      "Epoch [4/50] Batch 100/938 Loss D: 51.3652, loss G: -3.9673\n",
      "Epoch [4/50] Batch 200/938 Loss D: 45.7845, loss G: -2.9827\n",
      "Epoch [4/50] Batch 300/938 Loss D: 55.4200, loss G: -2.7905\n",
      "Epoch [4/50] Batch 400/938 Loss D: 64.7236, loss G: -3.2700\n",
      "Epoch [4/50] Batch 500/938 Loss D: 55.3159, loss G: -3.1053\n",
      "Epoch [4/50] Batch 600/938 Loss D: 55.3630, loss G: -3.4474\n",
      "Epoch [4/50] Batch 700/938 Loss D: 50.1364, loss G: -2.7360\n",
      "Epoch [4/50] Batch 800/938 Loss D: 52.7186, loss G: -2.7403\n",
      "Epoch [4/50] Batch 900/938 Loss D: 48.5482, loss G: -2.5948\n",
      "Epoch [5/50] Batch 0/938 Loss D: 56.5965, loss G: -3.5157\n",
      "Epoch [5/50] Batch 100/938 Loss D: 69.6476, loss G: -2.5759\n",
      "Epoch [5/50] Batch 200/938 Loss D: 51.2588, loss G: -2.5236\n",
      "Epoch [5/50] Batch 300/938 Loss D: 56.2814, loss G: -2.7281\n",
      "Epoch [5/50] Batch 400/938 Loss D: 63.3532, loss G: -2.8463\n",
      "Epoch [5/50] Batch 500/938 Loss D: 52.5078, loss G: -3.4386\n",
      "Epoch [5/50] Batch 600/938 Loss D: 63.6005, loss G: -2.5802\n",
      "Epoch [5/50] Batch 700/938 Loss D: 67.6053, loss G: -2.8269\n",
      "Epoch [5/50] Batch 800/938 Loss D: 53.0647, loss G: -3.1684\n",
      "Epoch [5/50] Batch 900/938 Loss D: 59.3536, loss G: -2.5274\n",
      "Epoch [6/50] Batch 0/938 Loss D: 53.3323, loss G: -2.9021\n",
      "Epoch [6/50] Batch 100/938 Loss D: 61.1328, loss G: -2.9034\n",
      "Epoch [6/50] Batch 200/938 Loss D: 62.9760, loss G: -2.4946\n",
      "Epoch [6/50] Batch 300/938 Loss D: 59.2064, loss G: -2.7198\n",
      "Epoch [6/50] Batch 400/938 Loss D: 70.4760, loss G: -1.8639\n",
      "Epoch [6/50] Batch 500/938 Loss D: 63.9346, loss G: -3.2779\n",
      "Epoch [6/50] Batch 600/938 Loss D: 66.1086, loss G: -2.8699\n",
      "Epoch [6/50] Batch 700/938 Loss D: 65.0916, loss G: -2.6033\n",
      "Epoch [6/50] Batch 800/938 Loss D: 58.5708, loss G: -2.6314\n",
      "Epoch [6/50] Batch 900/938 Loss D: 66.3473, loss G: -1.8286\n",
      "Epoch [7/50] Batch 0/938 Loss D: 64.2037, loss G: -2.1758\n",
      "Epoch [7/50] Batch 100/938 Loss D: 60.8811, loss G: -2.4454\n",
      "Epoch [7/50] Batch 200/938 Loss D: 55.2668, loss G: -2.5252\n",
      "Epoch [7/50] Batch 300/938 Loss D: 65.8172, loss G: -2.6794\n",
      "Epoch [7/50] Batch 400/938 Loss D: 68.8283, loss G: -2.8938\n",
      "Epoch [7/50] Batch 500/938 Loss D: 66.6415, loss G: -2.6405\n",
      "Epoch [7/50] Batch 600/938 Loss D: 76.8278, loss G: -2.2794\n",
      "Epoch [7/50] Batch 700/938 Loss D: 56.2469, loss G: -3.0022\n",
      "Epoch [7/50] Batch 800/938 Loss D: 57.9517, loss G: -1.9552\n",
      "Epoch [7/50] Batch 900/938 Loss D: 68.2921, loss G: -2.2558\n",
      "Epoch [8/50] Batch 0/938 Loss D: 63.9130, loss G: -2.2109\n",
      "Epoch [8/50] Batch 100/938 Loss D: 67.7734, loss G: -2.8871\n",
      "Epoch [8/50] Batch 200/938 Loss D: 65.1207, loss G: -2.6004\n",
      "Epoch [8/50] Batch 300/938 Loss D: 59.7608, loss G: -2.6753\n",
      "Epoch [8/50] Batch 400/938 Loss D: 61.8997, loss G: -2.5175\n",
      "Epoch [8/50] Batch 500/938 Loss D: 70.4818, loss G: -2.8428\n",
      "Epoch [8/50] Batch 600/938 Loss D: 63.1375, loss G: -2.5861\n",
      "Epoch [8/50] Batch 700/938 Loss D: 66.1730, loss G: -3.8399\n",
      "Epoch [8/50] Batch 800/938 Loss D: 60.1323, loss G: -2.4160\n",
      "Epoch [8/50] Batch 900/938 Loss D: 65.9285, loss G: -2.2911\n",
      "Epoch [9/50] Batch 0/938 Loss D: 72.8893, loss G: -3.2375\n",
      "Epoch [9/50] Batch 100/938 Loss D: 64.3651, loss G: -3.2474\n",
      "Epoch [9/50] Batch 200/938 Loss D: 69.5458, loss G: -2.6931\n",
      "Epoch [9/50] Batch 300/938 Loss D: 64.3792, loss G: -2.0481\n",
      "Epoch [9/50] Batch 400/938 Loss D: 62.1471, loss G: -2.1581\n",
      "Epoch [9/50] Batch 500/938 Loss D: 63.3470, loss G: -2.7239\n",
      "Epoch [9/50] Batch 600/938 Loss D: 64.2097, loss G: -2.5523\n",
      "Epoch [9/50] Batch 700/938 Loss D: 64.9168, loss G: -2.2909\n",
      "Epoch [9/50] Batch 800/938 Loss D: 63.5139, loss G: -2.3519\n",
      "Epoch [9/50] Batch 900/938 Loss D: 69.2770, loss G: -2.3538\n",
      "Epoch [10/50] Batch 0/938 Loss D: 68.4605, loss G: -3.1543\n",
      "Epoch [10/50] Batch 100/938 Loss D: 61.5910, loss G: -2.0866\n",
      "Epoch [10/50] Batch 200/938 Loss D: 61.9893, loss G: -3.8300\n",
      "Epoch [10/50] Batch 300/938 Loss D: 66.4950, loss G: -2.4119\n",
      "Epoch [10/50] Batch 400/938 Loss D: 68.5597, loss G: -2.6123\n",
      "Epoch [10/50] Batch 500/938 Loss D: 65.9904, loss G: -2.1497\n",
      "Epoch [10/50] Batch 600/938 Loss D: 70.2641, loss G: -2.8271\n",
      "Epoch [10/50] Batch 700/938 Loss D: 68.4433, loss G: -2.4035\n",
      "Epoch [10/50] Batch 800/938 Loss D: 61.5885, loss G: -2.2067\n",
      "Epoch [10/50] Batch 900/938 Loss D: 63.1885, loss G: -2.0840\n",
      "Epoch [11/50] Batch 0/938 Loss D: 69.0049, loss G: -2.3903\n",
      "Epoch [11/50] Batch 100/938 Loss D: 65.5340, loss G: -2.2376\n",
      "Epoch [11/50] Batch 200/938 Loss D: 71.2212, loss G: -2.6982\n",
      "Epoch [11/50] Batch 300/938 Loss D: 65.5037, loss G: -2.1058\n",
      "Epoch [11/50] Batch 400/938 Loss D: 73.3567, loss G: -2.3347\n",
      "Epoch [11/50] Batch 500/938 Loss D: 64.8359, loss G: -1.8331\n",
      "Epoch [11/50] Batch 600/938 Loss D: 71.0035, loss G: -2.8445\n",
      "Epoch [11/50] Batch 700/938 Loss D: 66.9412, loss G: -2.2362\n",
      "Epoch [11/50] Batch 800/938 Loss D: 70.9332, loss G: -2.1857\n",
      "Epoch [11/50] Batch 900/938 Loss D: 61.7845, loss G: -2.6454\n",
      "Epoch [12/50] Batch 0/938 Loss D: 69.0124, loss G: -2.4236\n",
      "Epoch [12/50] Batch 100/938 Loss D: 68.6934, loss G: -2.4006\n",
      "Epoch [12/50] Batch 200/938 Loss D: 71.7122, loss G: -2.0847\n",
      "Epoch [12/50] Batch 300/938 Loss D: 73.6459, loss G: -2.0754\n",
      "Epoch [12/50] Batch 400/938 Loss D: 67.2975, loss G: -1.9250\n",
      "Epoch [12/50] Batch 500/938 Loss D: 63.1848, loss G: -1.8894\n",
      "Epoch [12/50] Batch 600/938 Loss D: 76.9163, loss G: -3.0337\n",
      "Epoch [12/50] Batch 700/938 Loss D: 66.1403, loss G: -2.2106\n",
      "Epoch [12/50] Batch 800/938 Loss D: 67.0677, loss G: -2.4674\n",
      "Epoch [12/50] Batch 900/938 Loss D: 57.9309, loss G: -2.0742\n",
      "Epoch [13/50] Batch 0/938 Loss D: 69.8930, loss G: -1.8293\n",
      "Epoch [13/50] Batch 100/938 Loss D: 66.1315, loss G: -2.1340\n",
      "Epoch [13/50] Batch 200/938 Loss D: 61.5092, loss G: -2.4663\n",
      "Epoch [13/50] Batch 300/938 Loss D: 62.1871, loss G: -2.3053\n",
      "Epoch [13/50] Batch 400/938 Loss D: 70.2034, loss G: -2.2601\n",
      "Epoch [13/50] Batch 500/938 Loss D: 65.5547, loss G: -2.2303\n",
      "Epoch [13/50] Batch 600/938 Loss D: 65.5250, loss G: -2.4334\n",
      "Epoch [13/50] Batch 700/938 Loss D: 58.1221, loss G: -2.6177\n",
      "Epoch [13/50] Batch 800/938 Loss D: 74.0910, loss G: -2.2234\n",
      "Epoch [13/50] Batch 900/938 Loss D: 62.3915, loss G: -2.0985\n",
      "Epoch [14/50] Batch 0/938 Loss D: 62.4340, loss G: -1.6585\n",
      "Epoch [14/50] Batch 100/938 Loss D: 63.1274, loss G: -2.4604\n",
      "Epoch [14/50] Batch 200/938 Loss D: 63.6232, loss G: -1.7761\n",
      "Epoch [14/50] Batch 300/938 Loss D: 64.7000, loss G: -2.7210\n",
      "Epoch [14/50] Batch 400/938 Loss D: 57.3671, loss G: -2.5988\n",
      "Epoch [14/50] Batch 500/938 Loss D: 55.7218, loss G: -2.2441\n",
      "Epoch [14/50] Batch 600/938 Loss D: 60.5954, loss G: -1.6503\n",
      "Epoch [14/50] Batch 700/938 Loss D: 62.0483, loss G: -2.6077\n",
      "Epoch [14/50] Batch 800/938 Loss D: 64.4138, loss G: -1.9138\n",
      "Epoch [14/50] Batch 900/938 Loss D: 66.0329, loss G: -3.2899\n",
      "Epoch [15/50] Batch 0/938 Loss D: 63.7616, loss G: -2.1267\n",
      "Epoch [15/50] Batch 100/938 Loss D: 58.4197, loss G: -1.8373\n",
      "Epoch [15/50] Batch 200/938 Loss D: 65.7190, loss G: -2.7171\n",
      "Epoch [15/50] Batch 300/938 Loss D: 61.6500, loss G: -2.8241\n",
      "Epoch [15/50] Batch 400/938 Loss D: 62.1558, loss G: -2.2663\n",
      "Epoch [15/50] Batch 500/938 Loss D: 58.6133, loss G: -2.3338\n",
      "Epoch [15/50] Batch 600/938 Loss D: 53.9460, loss G: -1.7450\n",
      "Epoch [15/50] Batch 700/938 Loss D: 65.9684, loss G: -1.6976\n",
      "Epoch [15/50] Batch 800/938 Loss D: 63.4801, loss G: -2.0026\n",
      "Epoch [15/50] Batch 900/938 Loss D: 58.7944, loss G: -1.8872\n",
      "Epoch [16/50] Batch 0/938 Loss D: 55.8134, loss G: -1.9811\n",
      "Epoch [16/50] Batch 100/938 Loss D: 61.3727, loss G: -2.2534\n",
      "Epoch [16/50] Batch 200/938 Loss D: 60.4453, loss G: -2.7387\n",
      "Epoch [16/50] Batch 300/938 Loss D: 67.2097, loss G: -2.5594\n",
      "Epoch [16/50] Batch 400/938 Loss D: 57.5303, loss G: -2.0515\n",
      "Epoch [16/50] Batch 500/938 Loss D: 63.7527, loss G: -1.9480\n",
      "Epoch [16/50] Batch 600/938 Loss D: 61.8602, loss G: -2.0885\n",
      "Epoch [16/50] Batch 700/938 Loss D: 64.5383, loss G: -1.9187\n",
      "Epoch [16/50] Batch 800/938 Loss D: 59.3622, loss G: -2.4924\n",
      "Epoch [16/50] Batch 900/938 Loss D: 66.7268, loss G: -1.8351\n",
      "Epoch [17/50] Batch 0/938 Loss D: 66.8644, loss G: -3.3272\n",
      "Epoch [17/50] Batch 100/938 Loss D: 64.5750, loss G: -2.4809\n",
      "Epoch [17/50] Batch 200/938 Loss D: 60.5974, loss G: -2.4729\n",
      "Epoch [17/50] Batch 300/938 Loss D: 64.8016, loss G: -1.9267\n",
      "Epoch [17/50] Batch 400/938 Loss D: 62.6381, loss G: -1.9858\n",
      "Epoch [17/50] Batch 500/938 Loss D: 58.2816, loss G: -2.1377\n",
      "Epoch [17/50] Batch 600/938 Loss D: 60.2878, loss G: -2.3634\n",
      "Epoch [17/50] Batch 700/938 Loss D: 58.9492, loss G: -2.1189\n",
      "Epoch [17/50] Batch 800/938 Loss D: 57.8372, loss G: -1.8520\n",
      "Epoch [17/50] Batch 900/938 Loss D: 62.7025, loss G: -2.0590\n",
      "Epoch [18/50] Batch 0/938 Loss D: 57.1865, loss G: -3.0933\n",
      "Epoch [18/50] Batch 100/938 Loss D: 56.9131, loss G: -2.2265\n",
      "Epoch [18/50] Batch 200/938 Loss D: 57.4779, loss G: -1.9699\n",
      "Epoch [18/50] Batch 300/938 Loss D: 58.3152, loss G: -2.1694\n",
      "Epoch [18/50] Batch 400/938 Loss D: 56.8956, loss G: -2.4069\n",
      "Epoch [18/50] Batch 500/938 Loss D: 57.6664, loss G: -2.0919\n",
      "Epoch [18/50] Batch 600/938 Loss D: 60.4474, loss G: -2.4695\n",
      "Epoch [18/50] Batch 700/938 Loss D: 59.5535, loss G: -2.4454\n",
      "Epoch [18/50] Batch 800/938 Loss D: 55.1308, loss G: -2.3604\n",
      "Epoch [18/50] Batch 900/938 Loss D: 59.7471, loss G: -1.8198\n",
      "Epoch [19/50] Batch 0/938 Loss D: 51.5531, loss G: -1.7360\n",
      "Epoch [19/50] Batch 100/938 Loss D: 55.0684, loss G: -2.1037\n",
      "Epoch [19/50] Batch 200/938 Loss D: 58.7638, loss G: -1.9359\n",
      "Epoch [19/50] Batch 300/938 Loss D: 57.2138, loss G: -2.4508\n",
      "Epoch [19/50] Batch 400/938 Loss D: 62.5684, loss G: -2.1110\n",
      "Epoch [19/50] Batch 500/938 Loss D: 53.8878, loss G: -1.9697\n",
      "Epoch [19/50] Batch 600/938 Loss D: 56.9785, loss G: -1.9159\n",
      "Epoch [19/50] Batch 700/938 Loss D: 54.0170, loss G: -1.8957\n",
      "Epoch [19/50] Batch 800/938 Loss D: 57.7912, loss G: -1.7306\n",
      "Epoch [19/50] Batch 900/938 Loss D: 55.7315, loss G: -1.8983\n",
      "Epoch [20/50] Batch 0/938 Loss D: 56.4938, loss G: -1.4073\n",
      "Epoch [20/50] Batch 100/938 Loss D: 59.1428, loss G: -2.6436\n",
      "Epoch [20/50] Batch 200/938 Loss D: 50.3536, loss G: -2.3324\n",
      "Epoch [20/50] Batch 300/938 Loss D: 52.6472, loss G: -2.2114\n",
      "Epoch [20/50] Batch 400/938 Loss D: 52.2131, loss G: -1.7377\n",
      "Epoch [20/50] Batch 500/938 Loss D: 54.7122, loss G: -1.8314\n",
      "Epoch [20/50] Batch 600/938 Loss D: 47.9804, loss G: -1.8747\n",
      "Epoch [20/50] Batch 700/938 Loss D: 53.0781, loss G: -2.2818\n",
      "Epoch [20/50] Batch 800/938 Loss D: 55.5251, loss G: -3.0533\n",
      "Epoch [20/50] Batch 900/938 Loss D: 49.6384, loss G: -1.7801\n",
      "Epoch [21/50] Batch 0/938 Loss D: 47.3392, loss G: -1.7674\n",
      "Epoch [21/50] Batch 100/938 Loss D: 48.4932, loss G: -1.8695\n",
      "Epoch [21/50] Batch 200/938 Loss D: 54.1192, loss G: -2.6460\n",
      "Epoch [21/50] Batch 300/938 Loss D: 50.8374, loss G: -2.2126\n",
      "Epoch [21/50] Batch 400/938 Loss D: 54.6770, loss G: -1.9073\n",
      "Epoch [21/50] Batch 500/938 Loss D: 53.4258, loss G: -2.2669\n",
      "Epoch [21/50] Batch 600/938 Loss D: 48.2753, loss G: -2.1299\n",
      "Epoch [21/50] Batch 700/938 Loss D: 52.3380, loss G: -2.4576\n",
      "Epoch [21/50] Batch 800/938 Loss D: 45.1131, loss G: -2.0274\n",
      "Epoch [21/50] Batch 900/938 Loss D: 49.2418, loss G: -1.9366\n",
      "Epoch [22/50] Batch 0/938 Loss D: 47.6581, loss G: -2.2616\n",
      "Epoch [22/50] Batch 100/938 Loss D: 53.9787, loss G: -2.4404\n",
      "Epoch [22/50] Batch 200/938 Loss D: 47.9690, loss G: -2.1569\n",
      "Epoch [22/50] Batch 300/938 Loss D: 46.1803, loss G: -1.7588\n",
      "Epoch [22/50] Batch 400/938 Loss D: 49.1962, loss G: -2.2183\n",
      "Epoch [22/50] Batch 500/938 Loss D: 45.7116, loss G: -2.4935\n",
      "Epoch [22/50] Batch 600/938 Loss D: 48.4128, loss G: -2.3401\n",
      "Epoch [22/50] Batch 700/938 Loss D: 45.8623, loss G: -1.8958\n",
      "Epoch [22/50] Batch 800/938 Loss D: 46.6081, loss G: -1.9087\n",
      "Epoch [22/50] Batch 900/938 Loss D: 41.3923, loss G: -1.8374\n",
      "Epoch [23/50] Batch 0/938 Loss D: 47.7037, loss G: -1.9457\n",
      "Epoch [23/50] Batch 100/938 Loss D: 51.0089, loss G: -2.1283\n",
      "Epoch [23/50] Batch 200/938 Loss D: 45.9956, loss G: -2.4013\n",
      "Epoch [23/50] Batch 300/938 Loss D: 44.6986, loss G: -2.2958\n",
      "Epoch [23/50] Batch 400/938 Loss D: 46.8312, loss G: -2.0173\n",
      "Epoch [23/50] Batch 500/938 Loss D: 47.0916, loss G: -1.7542\n",
      "Epoch [23/50] Batch 600/938 Loss D: 45.2610, loss G: -1.9326\n",
      "Epoch [23/50] Batch 700/938 Loss D: 44.8708, loss G: -2.6089\n",
      "Epoch [23/50] Batch 800/938 Loss D: 50.2995, loss G: -2.0061\n",
      "Epoch [23/50] Batch 900/938 Loss D: 47.0412, loss G: -1.9842\n",
      "Epoch [24/50] Batch 0/938 Loss D: 44.7158, loss G: -1.8449\n",
      "Epoch [24/50] Batch 100/938 Loss D: 46.5667, loss G: -1.8997\n",
      "Epoch [24/50] Batch 200/938 Loss D: 40.9128, loss G: -1.7820\n",
      "Epoch [24/50] Batch 300/938 Loss D: 46.7383, loss G: -1.7772\n",
      "Epoch [24/50] Batch 400/938 Loss D: 47.5941, loss G: -2.1229\n",
      "Epoch [24/50] Batch 500/938 Loss D: 46.3609, loss G: -1.8853\n",
      "Epoch [24/50] Batch 600/938 Loss D: 42.4677, loss G: -2.4262\n",
      "Epoch [24/50] Batch 700/938 Loss D: 48.2045, loss G: -1.3946\n",
      "Epoch [24/50] Batch 800/938 Loss D: 44.2617, loss G: -2.1503\n",
      "Epoch [24/50] Batch 900/938 Loss D: 44.4674, loss G: -1.6961\n",
      "Epoch [25/50] Batch 0/938 Loss D: 44.9329, loss G: -1.8841\n",
      "Epoch [25/50] Batch 100/938 Loss D: 47.5937, loss G: -1.8876\n",
      "Epoch [25/50] Batch 200/938 Loss D: 42.1163, loss G: -2.2149\n",
      "Epoch [25/50] Batch 300/938 Loss D: 44.0724, loss G: -2.1045\n",
      "Epoch [25/50] Batch 400/938 Loss D: 45.5326, loss G: -1.9528\n",
      "Epoch [25/50] Batch 500/938 Loss D: 40.6165, loss G: -1.9922\n",
      "Epoch [25/50] Batch 600/938 Loss D: 38.4744, loss G: -2.1428\n",
      "Epoch [25/50] Batch 700/938 Loss D: 36.8908, loss G: -2.0548\n",
      "Epoch [25/50] Batch 800/938 Loss D: 38.1680, loss G: -1.6768\n",
      "Epoch [25/50] Batch 900/938 Loss D: 48.8171, loss G: -1.8480\n",
      "Epoch [26/50] Batch 0/938 Loss D: 43.3727, loss G: -1.8720\n",
      "Epoch [26/50] Batch 100/938 Loss D: 41.6779, loss G: -1.8032\n",
      "Epoch [26/50] Batch 200/938 Loss D: 38.2461, loss G: -1.5505\n",
      "Epoch [26/50] Batch 300/938 Loss D: 37.3984, loss G: -1.4748\n",
      "Epoch [26/50] Batch 400/938 Loss D: 40.9616, loss G: -1.7663\n",
      "Epoch [26/50] Batch 500/938 Loss D: 37.0013, loss G: -1.9882\n",
      "Epoch [26/50] Batch 600/938 Loss D: 37.3336, loss G: -1.7379\n",
      "Epoch [26/50] Batch 700/938 Loss D: 38.3620, loss G: -1.7024\n",
      "Epoch [26/50] Batch 800/938 Loss D: 39.6874, loss G: -2.0494\n",
      "Epoch [26/50] Batch 900/938 Loss D: 39.0117, loss G: -1.6126\n",
      "Epoch [27/50] Batch 0/938 Loss D: 39.3282, loss G: -2.0169\n",
      "Epoch [27/50] Batch 100/938 Loss D: 37.4413, loss G: -1.4756\n",
      "Epoch [27/50] Batch 200/938 Loss D: 38.5491, loss G: -1.6243\n",
      "Epoch [27/50] Batch 300/938 Loss D: 35.4018, loss G: -2.1372\n",
      "Epoch [27/50] Batch 400/938 Loss D: 37.1057, loss G: -1.5634\n",
      "Epoch [27/50] Batch 500/938 Loss D: 35.4705, loss G: -1.5322\n",
      "Epoch [27/50] Batch 600/938 Loss D: 32.9316, loss G: -0.9491\n",
      "Epoch [27/50] Batch 700/938 Loss D: 36.7658, loss G: -2.5331\n",
      "Epoch [27/50] Batch 800/938 Loss D: 38.1878, loss G: -2.0892\n",
      "Epoch [27/50] Batch 900/938 Loss D: 34.0229, loss G: -1.6577\n",
      "Epoch [28/50] Batch 0/938 Loss D: 39.1096, loss G: -2.0147\n",
      "Epoch [28/50] Batch 100/938 Loss D: 32.1491, loss G: -1.6866\n",
      "Epoch [28/50] Batch 200/938 Loss D: 34.9494, loss G: -1.5099\n",
      "Epoch [28/50] Batch 300/938 Loss D: 32.5963, loss G: -1.9730\n",
      "Epoch [28/50] Batch 400/938 Loss D: 36.3449, loss G: -2.2674\n",
      "Epoch [28/50] Batch 500/938 Loss D: 34.5494, loss G: -2.0796\n",
      "Epoch [28/50] Batch 600/938 Loss D: 38.1682, loss G: -2.2025\n",
      "Epoch [28/50] Batch 700/938 Loss D: 35.5585, loss G: -2.3561\n",
      "Epoch [28/50] Batch 800/938 Loss D: 35.3930, loss G: -1.4164\n",
      "Epoch [28/50] Batch 900/938 Loss D: 35.7536, loss G: -1.7703\n",
      "Epoch [29/50] Batch 0/938 Loss D: 30.7735, loss G: -1.7568\n",
      "Epoch [29/50] Batch 100/938 Loss D: 36.0300, loss G: -1.5890\n",
      "Epoch [29/50] Batch 200/938 Loss D: 34.1498, loss G: -1.2954\n",
      "Epoch [29/50] Batch 300/938 Loss D: 36.0926, loss G: -1.1822\n",
      "Epoch [29/50] Batch 400/938 Loss D: 33.0935, loss G: -1.5762\n",
      "Epoch [29/50] Batch 500/938 Loss D: 34.2900, loss G: -1.1438\n",
      "Epoch [29/50] Batch 600/938 Loss D: 34.0440, loss G: -1.5907\n",
      "Epoch [29/50] Batch 700/938 Loss D: 35.3053, loss G: -1.2523\n",
      "Epoch [29/50] Batch 800/938 Loss D: 34.3463, loss G: -1.4721\n",
      "Epoch [29/50] Batch 900/938 Loss D: 34.9894, loss G: -2.0984\n",
      "Epoch [30/50] Batch 0/938 Loss D: 37.4794, loss G: -1.9263\n",
      "Epoch [30/50] Batch 100/938 Loss D: 33.9611, loss G: -1.8369\n",
      "Epoch [30/50] Batch 200/938 Loss D: 33.1659, loss G: -1.7543\n",
      "Epoch [30/50] Batch 300/938 Loss D: 31.2086, loss G: -1.5311\n",
      "Epoch [30/50] Batch 400/938 Loss D: 30.8683, loss G: -1.9092\n",
      "Epoch [30/50] Batch 500/938 Loss D: 31.0398, loss G: -1.7114\n",
      "Epoch [30/50] Batch 600/938 Loss D: 32.7059, loss G: -1.8858\n",
      "Epoch [30/50] Batch 700/938 Loss D: 35.2343, loss G: -1.9752\n",
      "Epoch [30/50] Batch 800/938 Loss D: 34.1109, loss G: -1.7131\n",
      "Epoch [30/50] Batch 900/938 Loss D: 34.5504, loss G: -1.8813\n",
      "Epoch [31/50] Batch 0/938 Loss D: 31.3347, loss G: -1.6981\n",
      "Epoch [31/50] Batch 100/938 Loss D: 32.6068, loss G: -1.5495\n",
      "Epoch [31/50] Batch 200/938 Loss D: 32.8468, loss G: -1.5564\n",
      "Epoch [31/50] Batch 300/938 Loss D: 34.4555, loss G: -1.8911\n",
      "Epoch [31/50] Batch 400/938 Loss D: 32.4160, loss G: -1.6105\n",
      "Epoch [31/50] Batch 500/938 Loss D: 34.0899, loss G: -1.6236\n",
      "Epoch [31/50] Batch 600/938 Loss D: 32.6455, loss G: -1.4898\n",
      "Epoch [31/50] Batch 700/938 Loss D: 33.0141, loss G: -1.4564\n",
      "Epoch [31/50] Batch 800/938 Loss D: 34.6965, loss G: -1.6483\n",
      "Epoch [31/50] Batch 900/938 Loss D: 32.6452, loss G: -1.3360\n",
      "Epoch [32/50] Batch 0/938 Loss D: 34.8582, loss G: -2.0457\n",
      "Epoch [32/50] Batch 100/938 Loss D: 35.3223, loss G: -1.3260\n",
      "Epoch [32/50] Batch 200/938 Loss D: 32.5842, loss G: -1.5502\n",
      "Epoch [32/50] Batch 300/938 Loss D: 34.5537, loss G: -1.6516\n",
      "Epoch [32/50] Batch 400/938 Loss D: 31.7630, loss G: -1.4891\n",
      "Epoch [32/50] Batch 500/938 Loss D: 29.6928, loss G: -1.5425\n",
      "Epoch [32/50] Batch 600/938 Loss D: 33.9014, loss G: -2.0288\n",
      "Epoch [32/50] Batch 700/938 Loss D: 32.1183, loss G: -1.4900\n",
      "Epoch [32/50] Batch 800/938 Loss D: 30.9193, loss G: -1.0530\n",
      "Epoch [32/50] Batch 900/938 Loss D: 28.2301, loss G: -1.7125\n",
      "Epoch [33/50] Batch 0/938 Loss D: 28.0099, loss G: -1.6957\n",
      "Epoch [33/50] Batch 100/938 Loss D: 26.5674, loss G: -1.7644\n",
      "Epoch [33/50] Batch 200/938 Loss D: 31.4951, loss G: -1.4428\n",
      "Epoch [33/50] Batch 300/938 Loss D: 32.8502, loss G: -1.2686\n",
      "Epoch [33/50] Batch 400/938 Loss D: 35.8915, loss G: -2.0057\n",
      "Epoch [33/50] Batch 500/938 Loss D: 34.9167, loss G: -1.5565\n",
      "Epoch [33/50] Batch 600/938 Loss D: 31.0623, loss G: -1.8247\n",
      "Epoch [33/50] Batch 700/938 Loss D: 31.5168, loss G: -1.3931\n",
      "Epoch [33/50] Batch 800/938 Loss D: 32.9932, loss G: -1.7182\n",
      "Epoch [33/50] Batch 900/938 Loss D: 31.5947, loss G: -1.5277\n",
      "Epoch [34/50] Batch 0/938 Loss D: 30.4135, loss G: -1.4406\n",
      "Epoch [34/50] Batch 100/938 Loss D: 33.3568, loss G: -1.4700\n",
      "Epoch [34/50] Batch 200/938 Loss D: 34.5298, loss G: -1.8195\n",
      "Epoch [34/50] Batch 300/938 Loss D: 30.1338, loss G: -2.0218\n",
      "Epoch [34/50] Batch 400/938 Loss D: 31.1105, loss G: -1.3635\n",
      "Epoch [34/50] Batch 500/938 Loss D: 32.9425, loss G: -2.1853\n",
      "Epoch [34/50] Batch 600/938 Loss D: 31.0848, loss G: -1.9170\n",
      "Epoch [34/50] Batch 700/938 Loss D: 34.6235, loss G: -1.6300\n",
      "Epoch [34/50] Batch 800/938 Loss D: 29.2482, loss G: -1.2960\n",
      "Epoch [34/50] Batch 900/938 Loss D: 28.2976, loss G: -1.2221\n",
      "Epoch [35/50] Batch 0/938 Loss D: 32.8973, loss G: -2.2663\n",
      "Epoch [35/50] Batch 100/938 Loss D: 28.7368, loss G: -1.2919\n",
      "Epoch [35/50] Batch 200/938 Loss D: 27.9626, loss G: -1.8727\n",
      "Epoch [35/50] Batch 300/938 Loss D: 30.4669, loss G: -1.3002\n",
      "Epoch [35/50] Batch 400/938 Loss D: 30.1557, loss G: -1.6993\n",
      "Epoch [35/50] Batch 500/938 Loss D: 29.8669, loss G: -2.1079\n",
      "Epoch [35/50] Batch 600/938 Loss D: 29.2523, loss G: -1.4919\n",
      "Epoch [35/50] Batch 700/938 Loss D: 29.1610, loss G: -1.7811\n",
      "Epoch [35/50] Batch 800/938 Loss D: 27.2273, loss G: -1.6725\n",
      "Epoch [35/50] Batch 900/938 Loss D: 28.1991, loss G: -1.0585\n",
      "Epoch [36/50] Batch 0/938 Loss D: 28.1070, loss G: -2.2252\n",
      "Epoch [36/50] Batch 100/938 Loss D: 29.0629, loss G: -1.7224\n",
      "Epoch [36/50] Batch 200/938 Loss D: 28.6276, loss G: -1.8788\n",
      "Epoch [36/50] Batch 300/938 Loss D: 27.3589, loss G: -1.3239\n",
      "Epoch [36/50] Batch 400/938 Loss D: 25.2642, loss G: -1.2586\n",
      "Epoch [36/50] Batch 500/938 Loss D: 25.8800, loss G: -1.5840\n",
      "Epoch [36/50] Batch 600/938 Loss D: 29.3737, loss G: -1.8808\n",
      "Epoch [36/50] Batch 700/938 Loss D: 25.5097, loss G: -1.0392\n",
      "Epoch [36/50] Batch 800/938 Loss D: 26.6528, loss G: -1.5969\n",
      "Epoch [36/50] Batch 900/938 Loss D: 26.3673, loss G: -1.6360\n",
      "Epoch [37/50] Batch 0/938 Loss D: 29.1899, loss G: -1.9101\n",
      "Epoch [37/50] Batch 100/938 Loss D: 25.6523, loss G: -1.3473\n",
      "Epoch [37/50] Batch 200/938 Loss D: 28.5440, loss G: -2.7128\n",
      "Epoch [37/50] Batch 300/938 Loss D: 28.2992, loss G: -1.4847\n",
      "Epoch [37/50] Batch 400/938 Loss D: 29.6975, loss G: -1.4744\n",
      "Epoch [37/50] Batch 500/938 Loss D: 26.0345, loss G: -1.3277\n",
      "Epoch [37/50] Batch 600/938 Loss D: 28.3511, loss G: -2.4126\n",
      "Epoch [37/50] Batch 700/938 Loss D: 24.4326, loss G: -1.9111\n",
      "Epoch [37/50] Batch 800/938 Loss D: 28.7761, loss G: -1.8617\n",
      "Epoch [37/50] Batch 900/938 Loss D: 28.8536, loss G: -1.3041\n",
      "Epoch [38/50] Batch 0/938 Loss D: 25.9642, loss G: -1.3821\n",
      "Epoch [38/50] Batch 100/938 Loss D: 27.5238, loss G: -1.5264\n",
      "Epoch [38/50] Batch 200/938 Loss D: 28.4111, loss G: -1.5991\n",
      "Epoch [38/50] Batch 300/938 Loss D: 30.5815, loss G: -1.7261\n",
      "Epoch [38/50] Batch 400/938 Loss D: 31.6918, loss G: -1.5875\n",
      "Epoch [38/50] Batch 500/938 Loss D: 25.8461, loss G: -1.2717\n",
      "Epoch [38/50] Batch 600/938 Loss D: 27.5640, loss G: -2.3174\n",
      "Epoch [38/50] Batch 700/938 Loss D: 25.2655, loss G: -1.4189\n",
      "Epoch [38/50] Batch 800/938 Loss D: 27.7626, loss G: -1.6782\n",
      "Epoch [38/50] Batch 900/938 Loss D: 26.6899, loss G: -1.4473\n",
      "Epoch [39/50] Batch 0/938 Loss D: 24.3504, loss G: -1.3187\n",
      "Epoch [39/50] Batch 100/938 Loss D: 26.9955, loss G: -1.6612\n",
      "Epoch [39/50] Batch 200/938 Loss D: 23.7245, loss G: -1.8225\n",
      "Epoch [39/50] Batch 300/938 Loss D: 28.8111, loss G: -1.6299\n",
      "Epoch [39/50] Batch 400/938 Loss D: 24.8321, loss G: -2.1068\n",
      "Epoch [39/50] Batch 500/938 Loss D: 25.8669, loss G: -1.8314\n",
      "Epoch [39/50] Batch 600/938 Loss D: 26.5260, loss G: -1.2129\n",
      "Epoch [39/50] Batch 700/938 Loss D: 25.7558, loss G: -1.6367\n",
      "Epoch [39/50] Batch 800/938 Loss D: 23.9196, loss G: -1.2741\n",
      "Epoch [39/50] Batch 900/938 Loss D: 27.7031, loss G: -1.4816\n",
      "Epoch [40/50] Batch 0/938 Loss D: 26.5762, loss G: -1.7338\n",
      "Epoch [40/50] Batch 100/938 Loss D: 28.4212, loss G: -1.1546\n",
      "Epoch [40/50] Batch 200/938 Loss D: 26.6066, loss G: -1.5857\n",
      "Epoch [40/50] Batch 300/938 Loss D: 23.8265, loss G: -1.4601\n",
      "Epoch [40/50] Batch 400/938 Loss D: 26.3812, loss G: -1.3296\n",
      "Epoch [40/50] Batch 500/938 Loss D: 27.0261, loss G: -1.5185\n",
      "Epoch [40/50] Batch 600/938 Loss D: 26.0813, loss G: -1.5515\n",
      "Epoch [40/50] Batch 700/938 Loss D: 25.2170, loss G: -1.1825\n",
      "Epoch [40/50] Batch 800/938 Loss D: 22.9516, loss G: -1.9198\n",
      "Epoch [40/50] Batch 900/938 Loss D: 23.4087, loss G: -1.5554\n",
      "Epoch [41/50] Batch 0/938 Loss D: 25.6014, loss G: -1.6120\n",
      "Epoch [41/50] Batch 100/938 Loss D: 24.2445, loss G: -2.2137\n",
      "Epoch [41/50] Batch 200/938 Loss D: 23.9450, loss G: -1.1913\n",
      "Epoch [41/50] Batch 300/938 Loss D: 20.9768, loss G: -1.5033\n",
      "Epoch [41/50] Batch 400/938 Loss D: 22.1481, loss G: -2.2555\n",
      "Epoch [41/50] Batch 500/938 Loss D: 27.2741, loss G: -1.8892\n",
      "Epoch [41/50] Batch 600/938 Loss D: 24.3760, loss G: -1.7142\n",
      "Epoch [41/50] Batch 700/938 Loss D: 24.6136, loss G: -1.4159\n",
      "Epoch [41/50] Batch 800/938 Loss D: 22.8786, loss G: -1.5328\n",
      "Epoch [41/50] Batch 900/938 Loss D: 23.0910, loss G: -1.7162\n",
      "Epoch [42/50] Batch 0/938 Loss D: 24.3621, loss G: -1.7673\n",
      "Epoch [42/50] Batch 100/938 Loss D: 21.7688, loss G: -1.0245\n",
      "Epoch [42/50] Batch 200/938 Loss D: 25.3923, loss G: -1.2401\n",
      "Epoch [42/50] Batch 300/938 Loss D: 23.8032, loss G: -1.5585\n",
      "Epoch [42/50] Batch 400/938 Loss D: 23.0479, loss G: -1.4356\n",
      "Epoch [42/50] Batch 500/938 Loss D: 20.8503, loss G: -1.1115\n",
      "Epoch [42/50] Batch 600/938 Loss D: 24.6105, loss G: -1.6611\n",
      "Epoch [42/50] Batch 700/938 Loss D: 22.8296, loss G: -1.2518\n",
      "Epoch [42/50] Batch 800/938 Loss D: 20.7407, loss G: -1.4410\n",
      "Epoch [42/50] Batch 900/938 Loss D: 20.2916, loss G: -1.4031\n",
      "Epoch [43/50] Batch 0/938 Loss D: 21.7235, loss G: -1.6185\n",
      "Epoch [43/50] Batch 100/938 Loss D: 20.3505, loss G: -2.0552\n",
      "Epoch [43/50] Batch 200/938 Loss D: 20.1481, loss G: -1.1856\n",
      "Epoch [43/50] Batch 300/938 Loss D: 19.6463, loss G: -1.4718\n",
      "Epoch [43/50] Batch 400/938 Loss D: 22.3282, loss G: -1.3472\n",
      "Epoch [43/50] Batch 500/938 Loss D: 20.0814, loss G: -0.9484\n",
      "Epoch [43/50] Batch 600/938 Loss D: 19.9191, loss G: -1.1226\n",
      "Epoch [43/50] Batch 700/938 Loss D: 20.7702, loss G: -1.8203\n",
      "Epoch [43/50] Batch 800/938 Loss D: 22.7833, loss G: -1.6275\n",
      "Epoch [43/50] Batch 900/938 Loss D: 20.1827, loss G: -1.5682\n",
      "Epoch [44/50] Batch 0/938 Loss D: 21.1251, loss G: -1.8990\n",
      "Epoch [44/50] Batch 100/938 Loss D: 22.4635, loss G: -1.7841\n",
      "Epoch [44/50] Batch 200/938 Loss D: 19.5534, loss G: -1.1323\n",
      "Epoch [44/50] Batch 300/938 Loss D: 20.0036, loss G: -1.2549\n",
      "Epoch [44/50] Batch 400/938 Loss D: 20.1905, loss G: -1.9060\n",
      "Epoch [44/50] Batch 500/938 Loss D: 18.5993, loss G: -1.6545\n",
      "Epoch [44/50] Batch 600/938 Loss D: 20.5765, loss G: -1.5117\n",
      "Epoch [44/50] Batch 700/938 Loss D: 20.5359, loss G: -1.3572\n",
      "Epoch [44/50] Batch 800/938 Loss D: 20.1552, loss G: -1.8748\n",
      "Epoch [44/50] Batch 900/938 Loss D: 20.8299, loss G: -1.6721\n",
      "Epoch [45/50] Batch 0/938 Loss D: 16.5340, loss G: -1.5111\n",
      "Epoch [45/50] Batch 100/938 Loss D: 18.3482, loss G: -1.2571\n",
      "Epoch [45/50] Batch 200/938 Loss D: 20.4006, loss G: -1.9281\n",
      "Epoch [45/50] Batch 300/938 Loss D: 21.3841, loss G: -1.4232\n",
      "Epoch [45/50] Batch 400/938 Loss D: 18.1951, loss G: -1.3535\n",
      "Epoch [45/50] Batch 500/938 Loss D: 18.2279, loss G: -1.2643\n",
      "Epoch [45/50] Batch 600/938 Loss D: 18.7127, loss G: -1.5580\n",
      "Epoch [45/50] Batch 700/938 Loss D: 20.7491, loss G: -1.8236\n",
      "Epoch [45/50] Batch 800/938 Loss D: 19.6818, loss G: -1.1816\n",
      "Epoch [45/50] Batch 900/938 Loss D: 19.5818, loss G: -1.5195\n",
      "Epoch [46/50] Batch 0/938 Loss D: 18.1306, loss G: -1.4178\n",
      "Epoch [46/50] Batch 100/938 Loss D: 19.3851, loss G: -1.5030\n",
      "Epoch [46/50] Batch 200/938 Loss D: 19.9361, loss G: -1.2023\n",
      "Epoch [46/50] Batch 300/938 Loss D: 19.7531, loss G: -1.6206\n",
      "Epoch [46/50] Batch 400/938 Loss D: 20.6661, loss G: -1.5317\n",
      "Epoch [46/50] Batch 500/938 Loss D: 21.5675, loss G: -1.9561\n",
      "Epoch [46/50] Batch 600/938 Loss D: 20.1232, loss G: -1.5234\n",
      "Epoch [46/50] Batch 700/938 Loss D: 18.6455, loss G: -1.4326\n",
      "Epoch [46/50] Batch 800/938 Loss D: 18.4367, loss G: -1.4010\n",
      "Epoch [46/50] Batch 900/938 Loss D: 18.9208, loss G: -1.2900\n",
      "Epoch [47/50] Batch 0/938 Loss D: 17.2030, loss G: -1.7793\n",
      "Epoch [47/50] Batch 100/938 Loss D: 16.9891, loss G: -1.9562\n",
      "Epoch [47/50] Batch 200/938 Loss D: 18.1595, loss G: -1.3109\n",
      "Epoch [47/50] Batch 300/938 Loss D: 20.4367, loss G: -1.4794\n",
      "Epoch [47/50] Batch 400/938 Loss D: 19.6834, loss G: -2.4595\n",
      "Epoch [47/50] Batch 500/938 Loss D: 19.5852, loss G: -1.2991\n",
      "Epoch [47/50] Batch 600/938 Loss D: 20.8803, loss G: -1.1346\n",
      "Epoch [47/50] Batch 700/938 Loss D: 19.3649, loss G: -1.6539\n",
      "Epoch [47/50] Batch 800/938 Loss D: 18.2317, loss G: -1.3083\n",
      "Epoch [47/50] Batch 900/938 Loss D: 17.6066, loss G: -1.4847\n",
      "Epoch [48/50] Batch 0/938 Loss D: 18.1012, loss G: -1.3362\n",
      "Epoch [48/50] Batch 100/938 Loss D: 19.6660, loss G: -2.0249\n",
      "Epoch [48/50] Batch 200/938 Loss D: 16.1459, loss G: -1.5005\n",
      "Epoch [48/50] Batch 300/938 Loss D: 19.8499, loss G: -1.5080\n",
      "Epoch [48/50] Batch 400/938 Loss D: 16.8704, loss G: -1.8906\n",
      "Epoch [48/50] Batch 500/938 Loss D: 15.9558, loss G: -1.1219\n",
      "Epoch [48/50] Batch 600/938 Loss D: 17.5064, loss G: -1.4576\n",
      "Epoch [48/50] Batch 700/938 Loss D: 18.3117, loss G: -1.7967\n",
      "Epoch [48/50] Batch 800/938 Loss D: 18.8865, loss G: -1.7276\n",
      "Epoch [48/50] Batch 900/938 Loss D: 18.5716, loss G: -1.4798\n",
      "Epoch [49/50] Batch 0/938 Loss D: 20.3386, loss G: -1.1600\n",
      "Epoch [49/50] Batch 100/938 Loss D: 17.9841, loss G: -1.4479\n",
      "Epoch [49/50] Batch 200/938 Loss D: 17.8029, loss G: -1.5826\n",
      "Epoch [49/50] Batch 300/938 Loss D: 19.7595, loss G: -1.8878\n",
      "Epoch [49/50] Batch 400/938 Loss D: 17.3879, loss G: -1.3226\n",
      "Epoch [49/50] Batch 500/938 Loss D: 17.3100, loss G: -1.3494\n",
      "Epoch [49/50] Batch 600/938 Loss D: 17.1976, loss G: -1.7657\n",
      "Epoch [49/50] Batch 700/938 Loss D: 15.9482, loss G: -1.8235\n",
      "Epoch [49/50] Batch 800/938 Loss D: 17.5232, loss G: -1.8339\n",
      "Epoch [49/50] Batch 900/938 Loss D: 15.9104, loss G: -1.4436\n"
     ]
    }
   ],
   "source": [
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize(32),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5,), (0.5,))\n",
    "])\n",
    "\n",
    "dataset = datasets.MNIST(root=\"dataset/\", train=True, transform=transform, download=True)\n",
    "loader = DataLoader(dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "\n",
    "for epoch in range(50):\n",
    "    for batch_idx, (real, _) in enumerate(loader):\n",
    "        loss_c, loss_g = train_step(real)\n",
    "        \n",
    "        if batch_idx % 100 == 0:\n",
    "            print(f\"Epoch [{epoch}/50] Batch {batch_idx}/{len(loader)} Loss D: {loss_c:.4f}, loss G: {loss_g:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "81c6e236",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x800 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import torchvision.utils as vutils\n",
    "import numpy as np\n",
    "\n",
    "def show_generated_images(generator, num_images=16, z_dim=512, device=\"cpu\"):\n",
    "    generator.eval() # Set to evaluation mode\n",
    "    with torch.no_grad():\n",
    "        # 1. Generate random noise\n",
    "        noise = torch.randn(num_images, z_dim).to(device)\n",
    "        \n",
    "        # 2. Generate images\n",
    "        fake_images = generator(noise).detach().cpu()\n",
    "        \n",
    "        # 3. Create a grid (nrow is images per row)\n",
    "        grid = vutils.make_grid(fake_images, nrow=4, normalize=True, value_range=(-1, 1))\n",
    "        \n",
    "        # 4. Plot using Matplotlib\n",
    "        plt.figure(figsize=(8, 8))\n",
    "        plt.axis(\"off\")\n",
    "        plt.title(\"Generated Images\")\n",
    "        # Permute from (C, H, W) to (H, W, C) for Matplotlib\n",
    "        plt.imshow(np.transpose(grid, (1, 2, 0)))\n",
    "        plt.show()\n",
    "\n",
    "# To use it:\n",
    "show_generated_images(gen, num_images=16, z_dim=Z_DIM, device=DEVICE)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
