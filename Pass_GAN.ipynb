{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "01017f54",
   "metadata": {},
   "source": [
    "### Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "e2f13fe2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.cuda.amp import  GradScaler\n",
    "from torch.amp import autocast\n",
    "import string\n",
    "import time \n",
    "import numpy as np "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "62510f87",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch._utils\n",
    "\n",
    "if not hasattr(torch, '_utils'):\n",
    "    torch._utils = torch.utils._utils\n",
    "\n",
    
    "if not hasattr(torch, '_utils_internal'):\n",
    "    torch._utils_internal = torch._utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "dd937507",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.backends.cudnn.benchmark = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "af25d02f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n"
     ]
    }
   ],
   "source": [
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"Using {DEVICE} device\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "339613b7",
   "metadata": {},
   "source": [
    "### Data Preprocessing & Utilities "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "0c4a0e76",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PassUtils:\n",
    "    def __init__(self , seq_len = 14):\n",
    "        self.seq_len = seq_len\n",
    "        self.charset = string.printable[:-5]\n",
    "        self.char_to_int = {char: i for i , char in enumerate(self.charset)}\n",
    "        self.int_to_char = {i: char for i , char in enumerate(self.charset)}\n",
    "        self.vocab_size = len(self.charset)\n",
    "\n",
    "    def encode(self , password):\n",
    "        one_hot = torch.zeros(( self.vocab_size, self.seq_len))\n",
    "        for i , char in enumerate(password[:self.seq_len]):\n",
    "            if char in self.char_to_int:\n",
    "                one_hot[self.char_to_int[char],i] = 1.0\n",
    "        return one_hot\n",
    "\n",
    "    def decode(self , tensor):\n",
    "        if len(tensor.shape) == 2:\n",
    "            indices = torch.argmax(tensor , dim =0 )\n",
    "        else:\n",
    "            indices = torch.argmax(tensor , dim =1 )\n",
    "        return \"\".join([self.int_to_char[idx.item()] for idx in indices]).strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "30013652",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dataset(Dataset):\n",
    "    def __init__(self , file_path , utils, limit = 1000000):\n",
    "        self.utils = utils \n",
    "        self.passwords = []\n",
    "        with open(file_path , \"r\" , encoding=\"utf-8\", errors = \"ignore\") as f:\n",
    "            #self.passwords = [line.strip() for line in f if 0 < len(line.strip()) <= self.utils.seq_len]\n",
    "            for line in f:\n",
    "                p = line.strip()\n",
    "                if 0< len(p) <= self.utils.seq_len:\n",
    "                    self.passwords.append(p)\n",
    "                if len(self.passwords) >= limit:\n",
    "                    break\n",
    "        print(f\"Loaded {len(self.passwords)} passwords from {file_path}\")\n",
    "    def __len__(self):\n",
    "        return len(self.passwords)\n",
    "    \n",
    "\n",
    "    def __getitem__(self , idx):\n",
    "        return self.utils.encode(self.passwords[idx])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e5b8be2",
   "metadata": {},
   "source": [
    "### Model Architectue "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "37c7a5e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResBlock(nn.Module):\n",
    "    def __init__(self , dim):\n",
    "        super().__init__()\n",
    "        self.res = nn.Sequential(\n",
    "            nn.ReLU(True),\n",
    "            nn.Conv1d(in_channels = dim , out_channels = dim , kernel_size = 3 , padding = 1 ),\n",
    "            nn.ReLU(True),\n",
    "            nn.Conv1d(in_channels = dim , out_channels = dim , kernel_size = 3 , padding = 1)\n",
    "        )\n",
    "\n",
    "    def forward(self , x):\n",
    "        return x + ( 0.3 * self.res(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "cd3e5bc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Generator(nn.Module):\n",
    "    def __init__(self , seq_len , vocab_size , hid_dim = 512):\n",
    "        super().__init__()\n",
    "        self.fc = nn.Linear(128 , hid_dim * seq_len)\n",
    "        self.stack = nn.Sequential( *[ResBlock(hid_dim) for _ in range(5)])\n",
    "        self.Conv_out = nn.Conv1d(in_channels = hid_dim , out_channels = vocab_size , kernel_size = 1)\n",
    "        self.seq_len , self.hid_dim  = seq_len , hid_dim\n",
    "    def forward(self , z):\n",
    "        out = self.fc(z).view( -1 , self.hid_dim , self.seq_len)\n",
    "        out = self.stack(out)\n",
    "        return F.softmax(self.Conv_out(out) , dim = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "264d848c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Discriminator(nn.Module):\n",
    "    def __init__(self, seq_len , vocab_size , hid_dim = 512):\n",
    "        super().__init__()\n",
    "        self.conv_in =  nn.Conv1d(in_channels = vocab_size , out_channels = hid_dim , kernel_size = 1)\n",
    "        self.stack = nn.Sequential( *[ResBlock(hid_dim) for _ in range(5)])\n",
    "        self.fc = nn.Linear(hid_dim * seq_len , 1)\n",
    "    \n",
    "\n",
    "    def forward(self , x):\n",
    "        out = self.conv_in(x)\n",
    "        out = self.stack(out)\n",
    "        return self.fc(out.view(out.size(0) , -1))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f5fe2a9",
   "metadata": {},
   "source": [
    "### Training and Penalties"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "74b4ca3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def GP(D , real , fake , device=DEVICE):\n",
    "    batch_size = real.size(0)\n",
    "    alpha = torch.rand(batch_size , 1 ,1).to(device)\n",
    "    interpolates = (alpha * real + (1 - alpha) * fake).requires_grad_(True)\n",
    "    d_interpolates = D(interpolates)\n",
    "    grads = torch.autograd.grad(d_interpolates , interpolates , grad_outputs = torch.ones_like(d_interpolates) , create_graph = True)[0]\n",
    "    return ((grads.view(grads.size(0) , -1).norm(2 , dim = 1) - 1) ** 2).mean()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "0a92de78",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(epochs=10, batch_size=64, device=DEVICE):\n",
    "    utils = PassUtils(seq_len=10)\n",
    "    dataset = Dataset(\"rockyou-train.txt\", utils) \n",
    "    dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True, num_workers=0)\n",
    "\n",
    "    G = Generator(10,utils.vocab_size).to(device)\n",
    "    D = Discriminator(10, utils.vocab_size).to(device)\n",
    "    \n",
    "    optim_G = torch.optim.Adam(G.parameters(), lr=1e-4, betas=(0.5, 0.9))\n",
    "    optim_D = torch.optim.Adam(D.parameters(), lr=1e-4, betas=(0.5, 0.9))\n",
    "    \n",
    "    scaler = torch.amp.GradScaler('cuda')\n",
    "\n",
    "    print(f\"Starting training on {len(dataset)} passwords...\")\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        start_time = time.time()\n",
    "        G.train()\n",
    "        D.train()\n",
    "        \n",
    "        for i, real in enumerate(dataloader):\n",
    "            real = real.float().to(device)\n",
    "            current_batch_size = real.size(0)\n",
    "            \n",
    "    \n",
    "            optim_D.zero_grad()\n",
    "            z = torch.randn(current_batch_size, 128).to(device)\n",
    "            \n",
    "            with torch.amp.autocast('cuda'):\n",
    "                fake = G(z)\n",
    "                d_real = D(real)\n",
    "                d_fake = D(fake.detach())\n",
    "                gp_loss = GP(D, real, fake.detach(), device)\n",
    "    \n",
    "                d_loss = -torch.mean(d_real) + torch.mean(d_fake) + 10 * gp_loss\n",
    "\n",
    "            scaler.scale(d_loss).backward()\n",
    "            scaler.step(optim_D)\n",
    "    \n",
    "            if i % 5 == 0:\n",
    "                optim_G.zero_grad()\n",
    "                with torch.amp.autocast('cuda'):\n",
    "    \n",
    "                    gen_fake = G(z)\n",
    "                    d_gen_fake = D(gen_fake)\n",
    "                    g_loss = -torch.mean(d_gen_fake)\n",
    "\n",
    "                scaler.scale(g_loss).backward()\n",
    "                scaler.step(optim_G)\n",
    "            scaler.update() \n",
    "\n",
    "    \n",
    "            if i % 100 == 0:\n",
    "                \n",
    "                print(f\"Epoch {epoch+1}/{epochs} | Batch {i}/{len(dataloader)} | D Loss: {d_loss.item():.4f} | G Loss: {g_loss.item():.4f}\", end=\"\\r\")\n",
    "\n",
    "        end_time = time.time()\n",
    "        \n",
    "        \n",
    "        print(f\"\\n{'='*30}\")\n",
    "        print(f\"Epoch [{epoch+1}/{epochs}] Completed!\")\n",
    "        print(f\"D Loss: {d_loss.item():.4f} | G Loss: {g_loss.item():.4f} | Time: {end_time - start_time:.2f}s\")\n",
    "        \n",
    "        \n",
    "        G.eval()\n",
    "        with torch.no_grad():\n",
    "            sample_z = torch.randn(1, 128).to(device)\n",
    "            sample_pass = G(sample_z).squeeze(0)\n",
    "            print(f\"Sample Generated: {utils.decode(sample_pass)}\")\n",
    "        print(f\"{'='*30}\\n\")\n",
    "\n",
    "    return G, D, utils"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "485537df",
   "metadata": {},
   "source": [
    "### Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "250e4986",
   "metadata": {},
   "outputs": [],
   "source": [
    "def crack_meter(password, G, D, utils):\n",
    "    device = next(D.parameters()).device\n",
    "    D.eval()\n",
    "    \n",
    "    target_tensor = utils.encode(password).to(device).unsqueeze(0)\n",
    "    with torch.no_grad():\n",
    "        raw_score = D(target_tensor).item()\n",
    "        prob = torch.sigmoid(torch.tensor(raw_score)).item()\n",
    "\n",
    "    charset_size = utils.vocab_size\n",
    "    theoretical_combinations = charset_size ** len(password)\n",
    "    \n",
    "    guesses_needed = theoretical_combinations * (1 - prob + 1e-9)\n",
    "    gpu_speed = 1e11 \n",
    "    seconds = guesses_needed / gpu_speed\n",
    "\n",
    "    print(f\"\\n[ RESULTS FOR: {password} ]\")\n",
    "    print(f\"AI 'Likelihood' Score: {prob:.4f}\")\n",
    "    \n",
    "    if seconds < 1:\n",
    "        print(\"Estimated Crack Time: < 1 Second (AI found a common pattern)\")\n",
    "    elif seconds < 3600:\n",
    "        print(f\"Estimated Crack Time: ~{seconds/60:.2f} Minutes\")\n",
    "    else:\n",
    "        print(f\"Estimated Crack Time: ~{seconds/86400:.2f} Days\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7567826",
   "metadata": {},
   "source": [
    "### _____________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "47f678ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 1000000 passwords from rockyou-train.txt\n",
      "Starting training on 1000000 passwords...\n",
      "Epoch 1/10 | Batch 15600/15625 | D Loss: -1.2574 | G Loss: 0.6699\n",
      "==============================\n",
      "Epoch [1/10] Completed!\n",
      "D Loss: -1.1850 | G Loss: 0.8359 | Time: 495.67s\n",
      "Sample Generated: 994459|X9I\n",
      "==============================\n",
      "\n",
      "Epoch 2/10 | Batch 15600/15625 | D Loss: -1.2691 | G Loss: 0.7749\n",
      "==============================\n",
      "Epoch [2/10] Completed!\n",
      "D Loss: -1.1473 | G Loss: 0.7998 | Time: 486.37s\n",
      "Sample Generated: 02027227]^\n",
      "==============================\n",
      "\n",
      "Epoch 3/10 | Batch 15600/15625 | D Loss: -0.8296 | G Loss: 0.5049\n",
      "==============================\n",
      "Epoch [3/10] Completed!\n",
      "D Loss: -1.0702 | G Loss: 0.5527 | Time: 458.76s\n",
      "Sample Generated: yelveaK|V\"\n",
      "==============================\n",
      "\n",
      "Epoch 4/10 | Batch 15600/15625 | D Loss: -1.1382 | G Loss: 0.5854\n",
      "==============================\n",
      "Epoch [4/10] Completed!\n",
      "D Loss: -1.0282 | G Loss: 0.5747 | Time: 457.36s\n",
      "Sample Generated: capper*.<$\n",
      "==============================\n",
      "\n",
      "Epoch 5/10 | Batch 15600/15625 | D Loss: -0.9410 | G Loss: 0.8906\n",
      "==============================\n",
      "Epoch [5/10] Completed!\n",
      "D Loss: -1.0660 | G Loss: 0.9863 | Time: 457.91s\n",
      "Sample Generated: berlluiam;\n",
      "==============================\n",
      "\n",
      "Epoch 6/10 | Batch 15600/15625 | D Loss: -0.9262 | G Loss: 0.6328\n",
      "==============================\n",
      "Epoch [6/10] Completed!\n",
      "D Loss: -0.9410 | G Loss: 1.1191 | Time: 457.97s\n",
      "Sample Generated: 1baller]W@\n",
      "==============================\n",
      "\n",
      "Epoch 7/10 | Batch 15600/15625 | D Loss: -1.0656 | G Loss: 0.8398\n",
      "==============================\n",
      "Epoch [7/10] Completed!\n",
      "D Loss: -1.1338 | G Loss: 0.7642 | Time: 457.52s\n",
      "Sample Generated: pharai)@TT\n",
      "==============================\n",
      "\n",
      "Epoch 8/10 | Batch 15600/15625 | D Loss: -1.0912 | G Loss: 0.4421\n",
      "==============================\n",
      "Epoch [8/10] Completed!\n",
      "D Loss: -1.0536 | G Loss: 0.9902 | Time: 457.85s\n",
      "Sample Generated: 10020230_\n",
      "==============================\n",
      "\n",
      "Epoch 9/10 | Batch 15600/15625 | D Loss: -1.0472 | G Loss: 0.9341\n",
      "==============================\n",
      "Epoch [9/10] Completed!\n",
      "D Loss: -1.0525 | G Loss: 0.8965 | Time: 457.35s\n",
      "Sample Generated: caarike6&_\n",
      "==============================\n",
      "\n",
      "Epoch 10/10 | Batch 15600/15625 | D Loss: -1.2040 | G Loss: 1.0459\n",
      "==============================\n",
      "Epoch [10/10] Completed!\n",
      "D Loss: -1.1529 | G Loss: 0.9663 | Time: 457.83s\n",
      "Sample Generated: mankioQ*(=\n",
      "==============================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "gen, disc, utils_obj = train(epochs=10, batch_size=64)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "a8c32963",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[ RESULTS FOR: #S23xkdP&_ ]\n",
      "AI 'Likelihood' Score: 0.6007\n",
      "Estimated Crack Time: ~2766.94 Days\n",
      "\n",
      "[ RESULTS FOR: 7?{5hpJ4vQ ]\n",
      "AI 'Likelihood' Score: 0.5628\n",
      "Estimated Crack Time: ~3029.64 Days\n"
     ]
    }
   ],
   "source": [
    "crack_meter(\"#S23xkdP&_\", gen, disc, utils_obj)\n",
    "crack_meter(\"7?{5hpJ4vQ\", gen, disc, utils_obj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ddee5df",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
